{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "from skimage.util import view_as_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the dataset folder\n",
    "AllDatasetDirPath = r\"D:\\AI-Practical-Tasks\\2023-2024\\final\\Group D\\MangoLeafBD Dataset\"\n",
    "FolderList = my_list = os.listdir(AllDatasetDirPath)\n",
    "print(FolderList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset_dir):\n",
    "    names = [f\"haralick_{i+1}\" for i in range(13)]\n",
    "    names.append(\"classlabel\")\n",
    "    all_dataset_results = pd.DataFrame(columns=names)\n",
    "\n",
    "    for _, dirs, _ in os.walk(dataset_dir):\n",
    "        if len(dirs) > 0:\n",
    "            categories = dirs\n",
    "            break\n",
    "\n",
    "    for category in categories:\n",
    "        category_path = os.path.join(dataset_dir, category)\n",
    "        class_label = categories.index(category)\n",
    "        for filename in tqdm(os.listdir(category_path), desc=f\"Processing {category}\"):\n",
    "            imgpath = os.path.join(category_path, filename)\n",
    "            main_img = cv2.imread(imgpath)\n",
    "\n",
    "            # Convert the image to Grayscale\n",
    "            gray = cv2.cvtColor(main_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Texture based features\n",
    "            textures = mt.features.haralick(gray)\n",
    "            ht_mean = list(textures.mean(axis=0))\n",
    "            ht_mean.append(class_label)\n",
    "\n",
    "            # Append the feature vector to the DataFrame\n",
    "            df_temp = pd.DataFrame([ht_mean], columns=names)\n",
    "            all_dataset_results = pd.concat(\n",
    "                [all_dataset_results, df_temp], ignore_index=True\n",
    "            )\n",
    "\n",
    "    return all_dataset_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_dataset(AllDatasetDirPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"haralick_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_features(image_path):\n",
    "    # Read the image\n",
    "    main_img = cv2.imread(image_path)\n",
    "    original_img = main_img.copy()  # Create a copy for visualization\n",
    "\n",
    "    # Preprocessing\n",
    "    gray = cv2.cvtColor(main_img, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresholded = cv2.threshold(\n",
    "        gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU\n",
    "    )\n",
    "    contours, _ = cv2.findContours(\n",
    "        thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "    leaf_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # Extract features\n",
    "    x, y, w, h = cv2.boundingRect(leaf_contour)\n",
    "    area = cv2.contourArea(leaf_contour)\n",
    "    perimeter = cv2.arcLength(leaf_contour, True)\n",
    "    physiological_length = max(w, h)\n",
    "    physiological_width = min(w, h)\n",
    "    aspect_ratio = float(physiological_length) / physiological_width\n",
    "\n",
    "    # Visualize the image with features overlay\n",
    "    cv2.rectangle(\n",
    "        original_img, (x, y), (x + w, y + h), (0, 255, 0), 2\n",
    "    )  # Draw bounding box\n",
    "\n",
    "    # Annotate extracted features\n",
    "    text = (\n",
    "        f\"Area: {area:.2f}, Perimeter: {perimeter:.2f},Aspect Ratio: {aspect_ratio:.2f}\"\n",
    "    )\n",
    "    cv2.putText(\n",
    "        original_img,\n",
    "        text,\n",
    "        (0, y + 300),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.266,\n",
    "        (0, 0, 0),\n",
    "        1,\n",
    "        cv2.LINE_AA,\n",
    "    )\n",
    "\n",
    "    # Display the image with annotations\n",
    "    plt.figure(figsize=(10, 18))\n",
    "    plt.imshow(cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Image with Extracted Features Overlay\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "image_path = r\"D:\\AI-Practical-Tasks\\2023-2024\\final\\Group D\\MangoLeafBD Dataset\\Anthracnose\\20211008_124249 (Custom).jpg\"  # Replace this with the path to your image file\n",
    "overlay_features(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image\n",
    "img_path = r\"D:\\AI-Practical-Tasks\\2023-2024\\final\\Group D\\MangoLeafBD Dataset\\Anthracnose\\20211008_124249 (Custom).jpg\"  # Replace with the actual path of your image\n",
    "main_img = cv2.imread(img_path)\n",
    "\n",
    "# Convert the image to Grayscale\n",
    "gray = cv2.cvtColor(main_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Extract SIFT features\n",
    "sift = cv2.SIFT_create()\n",
    "keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "sift_features = (\n",
    "    descriptors.flatten() if descriptors is not None else np.zeros(128)\n",
    ")  # Assuming 128-dimensional SIFT descriptors\n",
    "\n",
    "# Compute HOG features\n",
    "hogg = cv2.HOGDescriptor()\n",
    "hog_features = hogg.compute(gray).flatten()\n",
    "\n",
    "# Extract LBP features\n",
    "lbp_radius = 3\n",
    "lbp_points = 8 * lbp_radius\n",
    "lbp = local_binary_pattern(gray, lbp_points, lbp_radius, method=\"uniform\")\n",
    "lbp_hist, _ = np.histogram(\n",
    "    lbp.ravel(), bins=np.arange(0, lbp_points + 3), range=(0, lbp_points + 2)\n",
    ")\n",
    "lbp_features = lbp_hist / np.sum(lbp_hist)\n",
    "\n",
    "# Extract Haralick texture features\n",
    "textures = mh.features.haralick(gray)\n",
    "ht_mean = textures.mean(axis=0)\n",
    "haralick_features = ht_mean[:14]  # Assuming 14 Haralick features\n",
    "\n",
    "# Compute Canny edges\n",
    "edges = cv2.Canny(gray, 100, 200)\n",
    "\n",
    "# Display the extracted features\n",
    "print(\n",
    "    \"SIFT Features:\", sift_features[:2]\n",
    ")  # Displaying first 2 SIFT features as an example\n",
    "print(\n",
    "    \"HOG Features:\", hog_features[:2]\n",
    ")  # Displaying first 2 HOG features as an example\n",
    "print(\n",
    "    \"LBP Features:\", lbp_features[:2]\n",
    ")  # Displaying first 2 LBP features as an example\n",
    "print(\n",
    "    \"Haralick Features:\", haralick_features[:2]\n",
    ")  # Displaying first 2 Haralick features as an example\n",
    "\n",
    "# Visualizing LBP Features\n",
    "plt.subplot(1, 2, 1)\n",
    "lbp_img = lbp.astype(np.uint8)  # Convert LBP features to uint8 for visualization\n",
    "plt.imshow(lbp_img, cmap=\"gray\")\n",
    "plt.title(\"Local Binary Patterns (LBP)\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Visualizing Canny Edges\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(edges, cmap=\"gray\")\n",
    "plt.title(\"Canny Edges\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_features(gray):\n",
    "    # Extract SIFT features\n",
    "    gray = cv2.resize(gray, (100, 100))\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    sift_features = descriptors.flatten() if descriptors is not None else np.zeros(128)\n",
    "\n",
    "    return sift_features\n",
    "\n",
    "\n",
    "def create_dataset(dataset_dir):\n",
    "    names = [\"SIFT\"]\n",
    "\n",
    "    all_dataset_results = pd.DataFrame(columns=names)\n",
    "\n",
    "    categories = next(os.walk(dataset_dir))[1]\n",
    "\n",
    "    for category in categories:\n",
    "        category_path = os.path.join(dataset_dir, category)\n",
    "        class_label = categories.index(category)\n",
    "        for filename in tqdm(os.listdir(category_path), desc=f\"Processing {category}\"):\n",
    "            imgpath = os.path.join(category_path, filename)\n",
    "            main_img = cv2.imread(imgpath)\n",
    "\n",
    "            # Convert the image to Grayscale\n",
    "            gray = cv2.cvtColor(main_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Calculate features\n",
    "            features = calculate_features(gray)\n",
    "\n",
    "            # Append the feature vector to the DataFrame\n",
    "            df_temp = pd.DataFrame([[features]], columns=names)\n",
    "            df_temp[\"classlabel\"] = class_label\n",
    "            all_dataset_results = pd.concat(\n",
    "                [all_dataset_results, df_temp], ignore_index=True\n",
    "            )\n",
    "\n",
    "    return all_dataset_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_dataset(AllDatasetDirPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"features1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an example image\n",
    "image = io.imread(\n",
    "    r\"D:\\AI-Practical-Tasks\\2023-2024\\final\\Group D\\MangoLeafBD Dataset\\Anthracnose\\20211008_124249 (Custom).jpg\",\n",
    "    as_gray=True,\n",
    ")\n",
    "\n",
    "# HOG feature extraction\n",
    "hog_features, hog_image = hog(\n",
    "    image,\n",
    "    orientations=9,\n",
    "    pixels_per_cell=(8, 8),\n",
    "    cells_per_block=(3, 3),\n",
    "    visualize=True,\n",
    "    block_norm=\"L2-Hys\",\n",
    ")\n",
    "\n",
    "# LBP feature extraction\n",
    "radius = 3\n",
    "n_points = 8 * radius\n",
    "lbp = local_binary_pattern(image, n_points, radius, method=\"uniform\")\n",
    "print(len(hog_features), lbp.shape)\n",
    "image_int = (image * 255).astype(int)  # Convert to integer type (0-255 range)\n",
    "\n",
    "# Haralick feature extraction\n",
    "textures = view_as_windows(image_int, (32, 32))\n",
    "haralick_features = mh.features.haralick(textures[:, :, 0, 0]).mean(axis=0)\n",
    "print(haralick_features)\n",
    "# Displaying the results or further processing as needed\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "plt.title(\"Original Image\")\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.imshow(hog_image, cmap=\"gray\")\n",
    "plt.title(\"HOG Features\")\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.imshow(lbp, cmap=\"gray\")\n",
    "plt.title(\"LBP Features\")\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.bar(range(len(haralick_features)), haralick_features)\n",
    "plt.title(\"Haralick Features\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset_dir):\n",
    "    names = [f\"hog_{i+1}\" for i in range(7200)]\n",
    "    names.append(\"classlabel\")\n",
    "    all_dataset_results = pd.DataFrame(columns=names)\n",
    "\n",
    "    for _, dirs, _ in os.walk(dataset_dir):\n",
    "        if len(dirs) > 0:\n",
    "            categories = dirs\n",
    "            break\n",
    "\n",
    "    for category in categories:\n",
    "        category_path = os.path.join(dataset_dir, category)\n",
    "        class_label = categories.index(category)\n",
    "        for filename in tqdm(os.listdir(category_path), desc=f\"Processing {category}\"):\n",
    "            imgpath = os.path.join(category_path, filename)\n",
    "            main_img = cv2.imread(imgpath)\n",
    "            main_img = cv2.resize(main_img, (100, 100))\n",
    "            gray = cv2.cvtColor(main_img, cv2.COLOR_BGR2GRAY)\n",
    "            hog_features = hog(\n",
    "                gray,\n",
    "                orientations=8,\n",
    "                pixels_per_cell=(8, 8),\n",
    "                cells_per_block=(3, 3),\n",
    "                visualize=False,\n",
    "                block_norm=\"L2-Hys\",\n",
    "            )\n",
    "            hog_features = list(hog_features)\n",
    "            hog_features.append(class_label)\n",
    "            # Append the feature vector to the DataFrame\n",
    "            df_temp = pd.DataFrame([hog_features], columns=names)\n",
    "            all_dataset_results = pd.concat(\n",
    "                [all_dataset_results, df_temp], ignore_index=True\n",
    "            )\n",
    "\n",
    "    return all_dataset_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_dataset(AllDatasetDirPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"hog_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset_dir):\n",
    "    names = [f\"lbp_{i+1}\" for i in range(10000)]\n",
    "    names.append(\"classlabel\")\n",
    "    all_dataset_results = pd.DataFrame(columns=names)\n",
    "\n",
    "    for _, dirs, _ in os.walk(dataset_dir):\n",
    "        if len(dirs) > 0:\n",
    "            categories = dirs\n",
    "            break\n",
    "\n",
    "    for category in categories:\n",
    "        category_path = os.path.join(dataset_dir, category)\n",
    "        class_label = categories.index(category)\n",
    "        for filename in tqdm(os.listdir(category_path), desc=f\"Processing {category}\"):\n",
    "            imgpath = os.path.join(category_path, filename)\n",
    "            main_img = cv2.imread(imgpath)\n",
    "            main_img = cv2.resize(main_img, (100, 100))\n",
    "            gray = cv2.cvtColor(main_img, cv2.COLOR_BGR2GRAY)\n",
    "            radius = 3\n",
    "            n_points = 8 * radius\n",
    "            lbp = local_binary_pattern(gray, n_points, radius, method=\"uniform\")\n",
    "            # Append the feature vector to the DataFrame\n",
    "            lbp = list(lbp.flatten())\n",
    "            lbp.append(class_label)\n",
    "            df_temp = pd.DataFrame([lbp], columns=names)\n",
    "            all_dataset_results = pd.concat(\n",
    "                [all_dataset_results, df_temp], ignore_index=True\n",
    "            )\n",
    "\n",
    "    return all_dataset_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_dataset(AllDatasetDirPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"lbp_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset_dir):\n",
    "    names = [f\"edge_{i+1}\" for i in range(10000)]\n",
    "    names.append(\"classlabel\")\n",
    "    all_dataset_results = pd.DataFrame(columns=names)\n",
    "\n",
    "    for _, dirs, _ in os.walk(dataset_dir):\n",
    "        if len(dirs) > 0:\n",
    "            categories = dirs\n",
    "            break\n",
    "\n",
    "    for category in categories:\n",
    "        category_path = os.path.join(dataset_dir, category)\n",
    "        class_label = categories.index(category)\n",
    "        for filename in tqdm(os.listdir(category_path), desc=f\"Processing {category}\"):\n",
    "            imgpath = os.path.join(category_path, filename)\n",
    "            main_img = cv2.imread(imgpath)\n",
    "            main_img = cv2.resize(main_img, (100, 100))\n",
    "            gray = cv2.cvtColor(main_img, cv2.COLOR_BGR2GRAY)\n",
    "            edges = cv2.Canny(gray, 100, 200)\n",
    "            edges = list(edges.flatten())\n",
    "            edges.append(class_label)\n",
    "            df_temp = pd.DataFrame([edges], columns=names)\n",
    "            all_dataset_results = pd.concat(\n",
    "                [all_dataset_results, df_temp], ignore_index=True\n",
    "            )\n",
    "\n",
    "    return all_dataset_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_dataset(AllDatasetDirPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"features/edges.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
